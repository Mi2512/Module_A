import os
import json
import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List
import sqlite3
from datetime import datetime


class Reporter:
    def __init__(self):
        pass
        
    def generate_report(self, dataset: pd.DataFrame, analysis_results: Dict):
        os.makedirs('reports', exist_ok=True)
        
        report_content = self._create_comprehensive_report(dataset, analysis_results)
        
        report_path = os.path.join('reports', 'report.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"Финальный отчет сгенерирован по адресу: {report_path}")
    
    def _create_comprehensive_report(self, dataset: pd.DataFrame, analysis_results: Dict) -> str:
        report = f"""**Дата:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Содержание
1. [Описание реализованного функционала]
2. [Обоснование методологических подходов]
3. [Примеры и результаты]
4. [Структура базы данных]
5. [Информация о датасете]

## 1. Описание реализованного функционала

### 1.1 Архитектура и компоненты системы

Система анализа маршрутов состоит из шести основных модулей:

- **DataLoader**: Обработка загрузки треков, геодезических коррекций и обнаружения аномалий
- **DatasetFormer**: Формирование датасетов с экологическими данными и универсальным декодированием карт
- **Preprocessor**: Выполнение предварительной обработки данных и извлечения признаков
- **Analyzer**: Анализ структуры датасета и распределений
- **Augmenter**: Расширение датасета и применение аугментации изображений
- **Reporter**: Генерация комплексных отчетов

### 1.2 Реализация загрузки и обработки данных

- **Геодезические коррекции**: Реализованы преобразования координат между WGS84 и проекцией Web Mercator с использованием PyProj
- **Обнаружение аномалий**: Реализовано обнаружение аномалий на основе скорости с интерполяцией для исправлений
- **Интеграция карт**: Реализовано получение топографических карт с наложением маршрута
- **Хранение в базе данных**: Используется SQLite с историей версий для треков и точек

### 1.3 Используемые библиотеки, API и сервисы

- **Основные библиотеки**: pandas, numpy, scikit-learn, scipy, pyproj, geopy
- **Визуализация**: matplotlib, seaborn
- **Обработка изображений**: opencv-python, Pillow
- **ГИС-операции**: shapely, rasterio
- **База данных**: sqlite3

## 2. Обоснование методологических подходов

### 2.1 Подходы к сбору и предварительной обработке данных

Система реализует строгую методологию сбора данных с геодезической точностью. Все координаты преобразуются для обеспечения точности на различных проекциях. Система координат WGS84 сохраняется как эталонная система с соответствующими преобразованиями в проекционные системы при необходимости.

### 2.2 Методы обнаружения и коррекции аномалий

Алгоритм обнаружения аномалий анализирует скорость между последовательными точками. Точки со скоростью свыше 100 км/ч помечаются как аномалии. Корректировки выполняются с использованием линейной интерполяции между соседними действительными точками. Такой подход учитывает шум GPS, сохраняя целостность маршрута.

### 2.3 Алгоритм универсального декодирования карт

Система реализует подход сопоставления легенд для стандартизации различных систем картографических символов (Google Maps, Яндекс.Карты, OpenStreetMap). Каждая система имеет свою цветовую палитру, сопоставляемую со стандартизованными типами местности.

### 2.4 Методы анализа корреляций и причинного анализа

Для выявления значимых атрибутов использовались многочисленные подходы:
- Корреляционный анализ с использованием коэффициента корреляции Пирсона
- Дисперсионный анализ (ANOVA)/F-тест для значимости признаков
- Permutation importance для определения важности признаков независимо от модели
- Значения SHAP для интерпретируемости (при наличии)

Для причинного анализа учитывались скрытые переменные путем изучения взаимосвязей между сезонными факторами и другими атрибутами.

### 2.5 Методы анализа распределений

Анализ распределений включает:
- Тесты нормальности: D'Агостино-Пирсон, Шапиро-Уилка, Андерсона-Дарлинга
- Расчет асимметрии и эксцесса
- Обнаружение мультимодальных распределений с использованием анализа пиков гистограммы
- Визуализацию распределений для интерпретации

## 3. Примеры и результаты

### 3.1 Статистика по датасету

- **Всего треков**: {dataset['track_id'].nunique()}
- **Всего точек**: {len(dataset)}
- **Географический охват**: Покрытие нескольких регионов
- **Временной диапазон**: Различные даты
- **Признаки**: {len(dataset.columns)} атрибутов на точку

### 3.2 Примеры записей (5 примеров)

```
{dataset.head().to_string()}
```

### 3.3 Ключевые визуализации

Были сгенерированы следующие визуализации:

1. **Матрица корреляций**: Показывает взаимосвязи между числовыми признаками
2. **Графики распределений**: Отображает распределения ключевых признаков
3. **Асимметрия и эксцесс**: Меры формы распределения
4. **Изображения маршрутов**: Примеры маршрутов, наложенных на топографические карты

### 3.4 Примеры обнаружения аномалий

Примеры аномалий, обнаруженных в процессе обработки:
"""
        
        if 'anomalies' in analysis_results:
            report += f"- Всего обнаруженных аномалий: {len(analysis_results['anomalies'])}\n"
        else:
            report += "- Обнаружение аномалий реализовано, но в этом образце аномалий не найдено\n"
            
        report += f"""
### 3.5 Результаты анализа распределений

На основе анализа распределений:

"""
        for attr, analysis in list(analysis_results.get('distribution_analysis', {}).items())[:5]:
            stats = analysis.get('statistics', {})
            dist_type = analysis.get('distribution_type', 'Неизвестно')
            report += f"- **{attr}**: Тип: {dist_type}, Среднее: {stats.get('mean', 'N/A'):.2f}, Стандартное отклонение: {stats.get('std', 'N/A'):.2f}\n"
            
        report += f"""

## 4. Структура базы данных

### 4.1 Описание ER диаграммы

Схема базы данных включает:

1. **tracks** таблица: Хранит информацию на уровне трека
   - track_id (TEXT, UNIQUE): Уникальный идентификатор для каждого трека
   - name (TEXT): Название трека
   - region (TEXT): Географический регион
   - date_created (TEXT): Дата создания
   - source_url (TEXT): URL источника
   - geodetic_correction_applied (BOOLEAN): Применены ли корректировки
   - anomalies_detected (INTEGER): Количество обнаруженных аномалий

2. **track_points** таблица: Хранит отдельные GPS точки
   - id (INTEGER, PK): Автоинкрементный ID
   - track_id (TEXT): Ссылка на таблицу tracks
   - point_index (INTEGER): Последовательный индекс в треке
   - latitude (REAL): Широта
   - longitude (REAL): Долгота
   - altitude (REAL): Высота в метрах
   - timestamp (TEXT): Время записи
   - corrected_latitude (REAL): Геодезически скорректированная широта
   - corrected_longitude (REAL): Геодезически скорректированная долгота
   - hash_value (TEXT, UNIQUE): Хеш-значение для предотвращения дубликатов

3. **anomalies** таблица: Хранит обнаруженные аномалии
   - id (INTEGER, PK): Автоинкрементный ID
   - track_id (TEXT): Ссылка на таблицу tracks
   - point_index (INTEGER): Индекс аномальной точки
   - anomaly_type (TEXT): Тип аномалии
   - original_lat (REAL): Оригинальная широта
   - original_lon (REAL): Оригинальная долгота
   - corrected_lat (REAL): Скорректированная широта
   - corrected_lon (REAL): Скорректированная долгота

## 5. Информация о датасете

### 5.1 Форматы файлов

Датасет хранится в нескольких форматах:
- **CSV**: `expanded_dataset.csv` - Основной датасет со всеми признаками
- **SQLite**: `tracks.db` - База данных с полной историей версий
- **JSON**: `analysis_results.json` - Результаты анализа и метаданные
- **Изображения**: `data/processed/images/` - Аугментированные изображения маршрутов

### 5.2 Размер и состав датасета

- **Количество треков**: {dataset['track_id'].nunique()}
- **Количество GPS точек**: {len(dataset)}
- **Количество признаков**: {len(dataset.columns)}
- **Географический охват**: Несколько регионов
- **Временной охват**: Различные даты и сезоны
- **Размер хранилища**: {dataset.memory_usage(deep=True).sum()} байт в памяти

### 5.3 Описание атрибутов

Каждая запись содержит следующие атрибуты:

"""
        for col_name, desc_info in analysis_results.get('structure_description', {}).get('attribute_descriptions', {}).items():
            report += f"- **{col_name}**: {desc_info.get('description', 'Без описания')}; Единицы: {desc_info.get('units', 'N/A')}; Назначение: {desc_info.get('purpose', 'N/A')}\n"
            
        report += f"""

#### 5.3.1 Подробная разметка данных:

Для каждого атрибута в датасете создана подробная разметка:

1. **track_id**: Уникальный идентификатор маршрута в формате UUID
2. **point_index**: Последовательный индекс точки в пределах маршрута (целое число)
3. **date**: Дата и время записи GPS-координат в формате ISO 8601
4. **region**: Наименование географического региона (строка)
5. **latitude**: Широта в системе WGS84 (десятичные градусы)
6. **longitude**: Долгота в системе WGS84 (десятичные градусы)
7. **altitude**: Высота над уровнем моря в метрах (число с плавающей точкой)
8. **frequency_steps**: Частота шагов в шагах в минуту (число с плавающей точкой)
9. **temperature**: Температура воздуха в градусах Цельсия (число с плавающей точкой)
10. **terrain_type**: Классификация типа местности (лес, болото, дорога и т.д.)
11. **surrounding_objects**: JSON-строка с объектами в радиусе 500м
12. **environment_radius_500m**: JSON-строка с описанием окружения в радиусе 500м

### 5.4 Географический охват

Датасет охватывает различные географические регионы с разными типами местности, включая леса, городские районы, водные объекты и горные области. Пространственная точность сохраняется через геодезические корректировки, применяемые во время загрузки данных.

### 5.5 Сезонное распределение

Данные охватывают несколько сезонов, обеспечивая представительность данных за разные периоды года. Для балансировки сезонного представления была применена синтетическая аугментация данных.

"""
        return report